---
title: Evaluating an attempt to restore summer fire in the Northern Great Plains
author:
- Devan Allen McGranahan and Jay P. Angerer
subtitle:  'Supplementary Information'
header-includes:
  - \usepackage{amsmath}
  - \renewcommand{\familydefault}{\sfdefault}
  - \usepackage[colorlinks=true, citecolor=blue, urlcolor=blue,linkcolor=blue, pdfborder={0 0 0}]{hyperref}
  - \urlstyle{same}
  - \usepackage{xcolor} 
  - \usepackage{booktabs}
  - \raggedright
  - \usepackage{listings}
output:
  pdf_document:
    highlight: tango
    keep_tex: yes
    toc: false
---

```{r setup, echo=FALSE, warning=FALSE, message = FALSE, results='hide'}
knitr::opts_chunk$set(message = FALSE, warning=FALSE, 
                      echo=FALSE, eval=TRUE)
pacman::p_load(tidyverse, xtable, wesanderson)
  BuGnPal = c( "#67A9CF" ,"#3690C0" ,"#02818A", "#016450")
  FFgrad = wes_palette("FantasticFox1")[c(3,2,4,5)]
  load('../data/NoFireIndices.Rdata')
  # load('../data/BurnIndices.Rdata')
  # load('../data/NoFireTrends.Rdata')
  load('../data/WxData.Rdata')
# some necessary things
  sys_yr <- 
    Sys.Date() %>%
      as.POSIXct(., '%Y-%M-%d') %>%
      year() 
  seasons <- 
    tibble(season = c('Spring', 'Summer'), 
           start = c(as.Date(paste0(sys_yr, '-04-25')), as.Date(paste0(sys_yr, '-08-07'))), 
           end = c(as.Date(paste0(sys_yr, '-05-25')), as.Date(paste0(sys_yr, '-08-27'))))
```

# Additional data and results 

## Seasonal trends 

```{r ndvi_trend, eval = TRUE, fig.cap="Seasonal trends in Landsat-derived NDVI for the study period. Green shaded areas span the first and last dates of completed burns in the spring and summer.", fig.height = 4, fig.width = 8}
NoFireIndices %>%
  group_by(ImageDate, pasture) %>%
    summarise(Mean = mean(ndvi), 
              SEM = sd(ndvi)/sqrt(n()), 
              .groups = 'drop') %>%
  mutate(ImageDate = as.Date(ImageDate, '%Y-%m-%d'), 
         Year = lubridate::year(ImageDate), 
         Year = as.factor(Year), 
         SampleDate = format(ImageDate, '%m-%d'), 
         SampleDate = as.Date(SampleDate, '%m-%d') ) %>%
  filter(Year != 2016) %>%
ggplot(aes(x = SampleDate, 
           color = Year, 
           fill = Year, 
           group = interaction(pasture, Year))) + theme_bw(14) +
  geom_rect(data= seasons, inherit.aes = FALSE,
              aes(xmin=start, xmax=end, ymin=-Inf, ymax=+Inf), 
              fill='#A1D99B', alpha=0.5) +
  geom_smooth(aes(y = Mean, group = Year),
              se = T,
              level = 0.99) +
  geom_errorbar(aes(ymin = Mean - SEM, 
                    ymax = Mean + SEM),
                alpha = 0.5) +
  geom_line(aes(y = Mean),
             alpha = 0.5) +
  labs(x = 'Image date', y = 'NDVI') + 
    scale_fill_manual(values = FFgrad) + 
  scale_color_manual(values = FFgrad) + 
  scale_x_date( date_breaks = 'month', 
                date_labels = '%b-%d', 
                minor_breaks = NULL) 
```

```{r precip_trend, eval = TRUE, fig.cap="Historical precipitation data for the entire 42-year period. Thick black line shows smoothed 42-yr trend, gray lines individual years, and colored lines study years. Green shaded areas span the first and last dates of completed burns in the spring and summer.", fig.height = 4, fig.width = 8}
  WxData$Rainfall %>% 
  mutate(day = day + years(1)) %>%
    filter(month(date) %in% c(04:09)) %>%
    separate(date, into = c('Year', 'Month', 'Day'),sep = '-') %>%
    group_by(Year) %>%
    mutate(CumPrecip = cumsum(Rainfall)) %>%
    ggplot(aes(x = day)) + theme_bw(14) +
    geom_rect(data= seasons, inherit.aes = FALSE,
              aes(xmin=start, xmax=end, ymin=-Inf, ymax=+Inf),
              fill='#A1D99B', alpha=0.5) +
    geom_line(aes(y = CumPrecip, group = Year),
              color = 'grey40', 
              alpha = 0.5) +
    geom_smooth(aes(y = CumPrecip),
                se = F,
                color = 'black',
                size = 1,
                level = 0.99) +
    geom_line(data = . %>%
                filter(as.numeric(Year) %in% c(2017:2020)) , 
              aes(y = CumPrecip, 
                  color = Year,
                  group = Year),
              size = 2) +
    labs(x = 'Day of year', y = 'Cumulative rainfall (mm)') + 
    scale_fill_manual(values = FFgrad) + 
    scale_color_manual(values = FFgrad) + 
    scale_x_date( date_breaks = 'month', 
                  date_labels = '%b-%d', 
                  minor_breaks = NULL)
```

\clearpage 

## $z$ scores for historical data by burn season

```{r historical_z, eval = TRUE, results='asis'}
load('../data/z_tab.Rdata')
 z_tab$hist %>%
  xtable(caption = 'Seasonal deviations in fuel conditions and fire weather for spring and summer burn seasons, relative to two decades (1990-1999, 2012-2022) as presented in Fig. 4. Anomalies determined by $z$ scores (parentheses) and categorized as above, below, or within 1 standard deviation of the mean for the given historical range. 2018 and 2019 were the years in which no summer burns were conducted; all spring burns were conducted in all years') %>%
   print(include.rownames = F, comment = F)
```

\newpage 

# Script 

This document provides script for fetching remotely-sensed imagery and processing results in the \textsf{R} statistical environment. 

## Remote sensing 

### Sentinel-2 

This \texttt{EvalScript} can be used in the [Copernicus browser](https://browser.dataspace.copernicus.eu/) as a Custom script to create a Custom visualization that can be exported as a 16-bit \texttt{.tiff} for raster analysis. 
The user must select the area of interest and imagery dates and is responsible for assessing cloudiness. 

\begin{lstlisting}[language=Java]

//VERSION=3
function setup() {
  return {
    input: ["B04", "B08", "B8A", "B11", "B12"],
    output: { bands: 2, sampleType: "UINT16" }
  };
}

function evaluatePixel(sample) {
  let nbr = index(sample.B08, sample.B12);
  let ndvi = index(sample.B08, sample.B04);
  // apply offset for UINT16 
  return [10000 * nbr + 10000, 
          10000 * ndvi + 10000]; 
}
\end{lstlisting}

\clearpage
### Landsat 

This script for [Google Earth Engine](https://code.earthengine.google.com/) exports a composited NDVI \texttt{.tiff} file to the user's Google Drive for the area of interest defined as \texttt{geometry} for an eight week period beginning with each date given in \texttt{listDate}. 
The script combines imagery from Landsat missions 5, 7, \& 8 and handles cloud masking. 

\begin{lstlisting}[language=Java]
// Geometry
var geometry: Polygon, 4 vertices
  type: Polygon
  coordinates: List (1 element)
    0: List (5 elements)
      0: [-99.51276195869765,46.71741699210676]
      1: [-99.42521465645156,46.71741699210676]
      2: [-99.42521465645156,46.778346255312734]
      3: [-99.51276195869765,46.778346255312734]
      4: [-99.51276195869765,46.71741699210676]
  geodesic: false

// Main script

var batch = require('users/fitoprincipe/geetools:batch');

///****variables that need to be changed by user
//****ADD google drive directory name that you want to download files to
var gdrivedir = 'landsat'

var listDate= ["1992-04-20", "1992-07-20", "1993-04-20", "1993-07-20", 
               "1994-04-20", "1994-07-20", "1995-04-20", "1995-07-20", 
               "1996-04-20", "1996-07-20", "1997-04-20", "1997-07-20", 
               "1998-04-20", "1998-07-20", "1999-04-20", "1999-07-20", 
               "2000-04-20", "2000-07-20", "2001-04-20", "2001-07-20", 
               "2002-04-20", "2002-07-20", "2003-04-20", "2003-07-20",
               "2004-04-20", "2004-07-20", "2005-04-20", "2005-07-20", 
               "2006-04-20", "2006-07-20", "2007-04-20", "2007-07-20", 
               "2008-04-20", "2008-07-20", "2009-04-20", "2009-07-20",
               "2010-04-20", "2010-07-20", "2011-04-20", "2011-07-20", 
               "2012-04-20", "2012-07-20", "2013-04-20", "2013-07-20", 
               "2014-04-20", "2014-07-20", "2015-04-20", "2015-07-20",
               "2016-04-20", "2016-07-20", "2017-04-20", "2017-07-20", 
               "2018-04-20", "2018-07-20", "2019-04-20", "2019-07-20", 
               "2020-04-20", "2020-07-20", "2021-04-20", "2021-07-20",
               "2022-04-20", "2022-07-20"]

listDate.forEach(function (listDate) {
  //yearRanges.forEach(function (yearRange) {
    exportTimeseries(listDate)
  })
//})
function exportTimeseries(listDate) {
  
  // Defines a base date/time for the following examples.
  var startDate = ee.Date(listDate);
  print(startDate, 'The start date/time');
  print(startDate.format('YYYYMMdd'))
  var sdate = startDate.format('YYYYMMdd')
  var endDate = startDate.advance(8, 'week')
  print(endDate, 'The end date/time');
  var edate = endDate.format('YYYYMMdd')
  
  print(endDate.format('YYYYMMdd'))

  //from https://developers.google.com/earth-engine/tutorials/
  //                community/extract-raster-values-for-points
  //function to mask cloud and shadow pixels
  function fmask(img) {
    var cloudShadowBitMask = 1 << 4;
    var cloudsBitMask = 1 << 3;
    var qa = img.select('QA_PIXEL');
    var mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0)
      .and(qa.bitwiseAnd(cloudsBitMask).eq(0));
    return img.updateMask(mask);
  }
  
  // Selects and renames bands of interest for Landsat OLI.
  function renameOli(img) {
    return img.select(
      ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'],
      ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']);
  }
  
  // Selects and renames bands of interest for TM/ETM+.
  function renameEtm(img) {
    return img.select(
      ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'],
      ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']);
  }
  
  // Prepares (cloud masks and renames) OLI images.
  function prepOli(img) {
    img = fmask(img);
    //img = lcfmask(img)
    img = renameOli(img);
    return img;
  }
  
  // Prepares (cloud masks and renames) TM/ETM+ images.
  function prepEtm(img) {
    img = fmask(img);
    //img = lcfmask(img)
    img = renameEtm(img);
    return img;
  }
  
  // Apply scaling factors
  function applyScaleFactors(image) {
    var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);
    var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);
    return image.addBands(opticalBands, null, true)
                .addBands(thermalBands, null, true);
  }
  
  // Get surface reflectance collections for Landsat
  // maps scaling factors and cloud masking functions 
  
  var oliCol = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
              .filter(ee.Filter.bounds(geometry))
              .map(applyScaleFactors)
              .map(prepOli);
  
  var etmCol = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')
                .filter(ee.Filter.bounds(geometry))
                .map(applyScaleFactors)
                .map(prepEtm);
  
  var tmCol = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')
              .filter(ee.Filter.bounds(geometry))
              .map(applyScaleFactors)
              .map(prepEtm) ;
  
  var landsatCol = oliCol.merge(etmCol).merge(tmCol)
                   .filterDate(startDate, endDate) ;
  
  // Calculate NDVI 
  var addIndices = function(image) {
     var ndvi = image.normalizedDifference(['NIR', 'Red'])
                .rename('ndvi').float();
  return image.addBands([ndvi]);
  };
  
  var indices = landsatCol.map(addIndices) 
                .select('ndvi');
  // Create composite of images from date range
    var composite = indices.mean() ; 
  
    var fileName = ee.Date(startDate) 
                  .format('yyyy-MM-dd')
                  .getInfo() ;

  Export.image.toDrive({
      image: composite,
      description: fileName,
      scale: 30,
      folder: 'landsat', 
      region: geometry
      });
}
\end{lstlisting}

\newpage 

## Analysis 

Because the analysis script assumes hundreds of imagery files and a large Excel file with 42 years of hourly weather observations have been saved locally, it cannot be run directly from this document but is provided here for transparency and reference. 

### Remotely sensed imagery 

\begin{lstlisting}[language=R] 

# Load necessary packages
# Note that package terra is required but is not loaded
# (called directly to not create conflicts with dplyr verbs)
  pacman::p_load(tidyverse, sf, stars, foreach, doSNOW)

# Load location boundaries (data not provided)
  cgrec_gpkg = './CGREC_PBG_26914.gpkg'

  pastures <- st_read(cgrec_gpkg, 'Pastures') 
  patches <- st_read(cgrec_gpkg, 'PasturePatches') 
#
# Get veg data for unburned pastures
#
  NoFirePts <- st_read(cgrec_gpkg, 'SamplePoints') %>%
                filter(location == 'Refuge')
  # Map to directory with Sentinel-2 imagery
    imagery_dir = 'C:/Path/To/Sentinel'
    images <- list.files(imagery_dir)
  # Use parallel processing to chug imagery
  { 
    begin = Sys.time() 
    pacman::p_load()
    cores = parallel::detectCores()
    cl <- makeCluster(cores, methods = F, useXDR = F)
    registerDoSNOW(cl)
    NoFireIndices <-
      foreach(i=1:length(images), 
              .combine = 'bind_rows',
              .errorhandling = 'remove', 
              .packages=c('tidyverse', 'sf')) %dopar% {
        image = images[i]
        image_path = paste0(imagery_dir, '/', image)
        ras <- terra::rast(image_path)
        names(ras) <- c('nbr', 'ndvi') 
        ras <- ras[['ndvi']]
        float = (ras-10000)/10000
        terra::extract(float,
          NoFirePts %>%
            select(pasture, sample) %>%
            terra::vect() , 
          FUN = mean, 
          bind = TRUE)  %>%
        st_as_sf() %>%
          as_tibble() %>%
        mutate(ImageDate = substr(image, 1, 10)) %>%
        select(ImageDate, pasture, sample, ndvi) 
            }
    stopCluster(cl)
  Sys.time() - begin 
  }
#
# Get fuel greenness and dNBR for completed burns
#
  fires <- st_read(cgrec_gpkg, 'FirePerimeters') %>%
              mutate(Year = as.factor(Year)) %>%
              filter(status == 'Completed') %>%
              unite('fire', c(unit, Pasture, Patch), sep = "-") %>%
              select(fire, Year, Season, PreBurn, PostBurn )
  SamplePts <- 
    st_read(cgrec_gpkg, 'SamplePointsRegular')
{ 
  begin = Sys.time() 
  pacman::p_load(foreach, doSNOW)
  cores = parallel::detectCores()
  cl <- makeCluster(cores , methods = F, useXDR = F)
  registerDoSNOW(cl)
  BurnIndices <-
    foreach(i=1:length(fires$fire), 
            .combine = 'bind_rows',
            .errorhandling = 'remove', 
            .packages=c('tidyverse', 'sf')) %dopar% {
              # Get fire
                fire = slice(fires, i)
              # Get sample points
                pts <-
                  fire %>%
                    st_intersection(SamplePts)
              # Get dates
                pre_date = fire$PreBurn
                post_date = fire$PostBurn
              # Fetch & process multi-band rasters
                # pre image
                  pre_image = images[substr(images, 1, 10) == pre_date]
                  pre_path = paste0(imagery_dir, '/', pre_image)
                  pre_ras <- terra::rast(pre_path) %>%
                                terra::crop(terra::vect(fire))
                  names(pre_ras) <- c('nbr', 'ndvi') 
                  pre_ras <-  (pre_ras-10000)/10000
                # post-fire
                  post_image = images[substr(images, 1, 10) == post_date]
                  post_path = paste0(imagery_dir, '/', post_image)
                  post_ras <- terra::rast(post_path)[[1]] %>%
                                terra::crop(terra::vect(fire))
                  post_ras = (post_ras-10000)/10000
                # Calculate dNBR & replace in pre-fire raster
                  d_ras = pre_ras['nbr'] - post_ras
                  names(d_ras) <- 'dNBR'
                  pre_ras[[1]] <- d_ras
              # Sample rasters
                 terra::extract( pre_ras,
                          pts %>%
                            select(-PostBurn) %>%
                            terra::vect() , 
                          FUN = mean, 
                          bind = TRUE)  %>%
                  st_as_sf() %>%
                    as_tibble() %>%
                    select(-geometry) 
            }
  stopCluster(cl)
  Sys.time() - begin 
}
#
# Get historical Landsat data for unburned pastures
#
  imagery_dir = 'C:/Path/To/Landsat'
  images <- list.files(imagery_dir)
  { 
    begin = Sys.time() 
    pacman::p_load(foreach, doSNOW)
    cores = parallel::detectCores()
    cl <- makeCluster(cores, methods = F, useXDR = F)
    registerDoSNOW(cl)
    NoFireTrends <-
      foreach(i=1:length(images), 
              .combine = 'bind_rows',
              .errorhandling = 'remove', 
              .packages=c('tidyverse', 'sf')) %dopar% {
                image = images[i]
                image_path = paste0(imagery_dir, '/', image)
                ras <- terra::rast(image_path)
                ras <- ras[['ndvi']]
                 terra::extract(ras,
                               NoFirePts %>%
                                 select(pasture, sample) %>%
                                 st_transform(4326) %>%
                                 terra::vect() , 
                               FUN = mean, 
                               bind = TRUE)  %>%
                  st_as_sf() %>%
                  as_tibble() %>%
                  mutate(ImageDate = tools::file_path_sans_ext(image))  %>%
                  select(ImageDate, pasture, sample, ndvi) 
              }
    stopCluster(cl)
    Sys.time() - begin 
  }
\end{lstlisting}

### Weather data 

This script wrangles the weather data downloaded from the [North Dakota Ag Weather Network's Streeter station](https://ndawn.ndsu.nodak.edu/station-info.html?station=48).

\begin{lstlisting}[language=R] 

pacman::p_load(tidyverse, readxl)

  sys_yr <- 
    Sys.Date() %>%
      as.POSIXct(., '%Y-%M-%d') %>%
      year() 
  seasons <- 
    tibble(season = c('Spring', 'Summer'), 
           start = c(as.Date(paste0(sys_yr, '-04-20')), 
                     as.Date(paste0(sys_yr, '-07-20'))), 
           end = c(as.Date(paste0(sys_yr, '06-10')), 
                   as.Date(paste0(sys_yr, '09-10'))))

BurnDays <- 
  read_xlsx('./data/BurnData.xlsx', 'BurnDays') %>%
  filter(is.na(certainty)) %>%
    mutate(date = paste(year, date), 
           date = as.Date(date, '%Y %B %d')) %>%
    select(date) %>%
  distinct() 

WxData <- lst() 
# Get daily data 
  DailyWx <- 
    read_xlsx('./data/CGREC_weather.xlsx', 'daily')
# Identify rainy days
  WxData$Rainfall <-
    DailyWx %>%
    select(Year, Month, Day, Rainfall) %>% 
    unite( c(Month, Day), col = 'day', sep = '-', remove = F) %>%
    mutate(day = as.Date(day, '%m-%d')  , 
           season = case_when(
             between(day, seasons$start[1], seasons$end[1]) ~'Spring', 
             between(day, seasons$start[2], seasons$end[2]) ~'Summer',
             TRUE ~ NA  ) ) %>% 
     unite( c(Year, Month, Day), col = 'date', sep = '-')

# Hourly data 
  WxData$HourlyWx <- 
    read_xlsx('./data/CGREC_weather.xlsx', 'hourly') %>%
    filter(between(Hour, 1000, 1700)) %>%
    unite( c(Year, Month, Day), col = 'date', sep = '-', remove = F) %>%
    unite( c(Month, Day), col = 'day', sep = '-', remove = F) %>%
    mutate(day = as.Date(day, '%m-%d'), 
           season = case_when(
             between(day, seasons$start[1], seasons$end[1]) ~'Spring', 
             between(day, seasons$start[2], seasons$end[2]) ~'Summer',
             TRUE ~ NA  ) ) %>%
    mutate(e = 6.11 * (10 ^ ( (7.5 * DewPoint)/ (237.3 + DewPoint) ) ), 
           es = 6.11 * (10 ^ ( (7.5 * AirTemp)/ (237.3 + AirTemp) ) ), 
           VPD = es - e) 
# Get burn day weather
  WxData$BurnDayWx <-
    HourlyWx  %>% 
    filter(date %in% BurnDays$date) %>%
    group_by(Year, date, season) %>%
    summarise_at(.vars = vars(c(DewPoint, RelHum, WindSpeed,VPD)),
                 .funs = c("mean")) %>%
    ungroup() %>%
    pivot_longer(names_to = 'variable', 
                 values_to = 'value', 
                 cols = DewPoint:VPD) 
\end{lstlisting}

### Statistical analysis 

\textsf{R} script for statistical analysis is organized by the manuscript figure for which the tests support. 

**Figure 1** 

\begin{lstlisting}[language=R]

# A: Test NDVI in study years across seasons 
  # Wrangle NDVI data from adjacent unburned pastures
    ndvi_dat <-
      NoFireIndices %>%
        group_by(ImageDate, pasture) %>%
        summarise(NDVI = median(ndvi) , 
                  .groups = 'drop') %>%
        mutate(ImageDate = as.Date(ImageDate, '%Y-%m-%d'), 
               Year = lubridate::year(ImageDate), 
               Year = as.factor(Year), 
               SampleDate = format(ImageDate, '%m-%d'), 
               SampleDate = as.Date(SampleDate, '%m-%d'), 
               season = case_when(
                 between(SampleDate, seasons$start[1], seasons$end[1]) ~ 'Spring',
                 between(SampleDate, seasons$start[2], seasons$end[2]) ~ 'Summer', 
                 TRUE ~ NA ) ) %>%
        filter(!is.na(season)) %>%
      select(pasture, Year, season, NDVI)
  # Fit mixed-effect models
    m0 <- lme4::lmer(NDVI ~ 1 + (1|Year), REML=FALSE, data = ndvi_dat) 
    m1 <- lme4::lmer(NDVI ~ season + (1|Year), REML=FALSE, data = ndvi_dat)
  # Compare models for significance of season term
    anova(m0, m1)
  
# B: Test for difference between seasons
  # Wrangle severity and NDVI data from burned pastures
    reg_dat <-
      BurnIndices  %>%
        group_by(Year, Season, fire) %>%
        summarize(dNBR = mean(dNBR), 
                  NDVI = mean(ndvi), 
                  .groups = 'drop') %>%
        separate(fire, into=c('block','pasture','patch'), sep='-')
  # Fit models
    m0 <- lme4::glmer(dNBR ~ 1 + (1|block) , 
                  family = Gamma(link = "identity"), 
                  data = reg_dat)
    m1 <- lme4::glmer(dNBR ~ NDVI + (1|block), 
                  family = Gamma(link = "identity"), 
                  data = reg_dat)
    m2 <- lme4::glmer(dNBR ~ NDVI + Season + (1|block) , 
                      family = Gamma(link = "identity"), 
                      data = reg_dat)
  # Compare models
    anova(m0, m1, m2)

\end{lstlisting}

**Figure 2** 

Calculate $z$ scores. 

\begin{lstlisting}[language=R]
# NDVI x burn season 
  ndvi_z <-
    LandsatSums %>%
    filter(year %in% c(2017:2020), 
           index == 'ndvi') %>%
    group_by(year, season) %>%
    summarize(Mean = mean(Value), 
              .groups = 'drop') %>%
    left_join(by = 'season', 
              LandsatSums %>%
                filter(index == 'ndvi') %>%
                group_by(season) %>%
                summarize(HistMean = mean(Value, na.rm = T),
                          HistSD = sd(Value, na.rm = T),
                          .groups = 'drop') ) %>%
    mutate(z = (Mean - HistMean)/HistSD, 
           interp = case_when(
             z < -1 ~ "Below", 
             z > 1 ~ "Above", 
             TRUE ~ 'Within' ) )
# YTD precip x burn season 
  prcp <- 
    WxData$Rainfall %>% 
    filter(month(date) %in% c(04:09)) %>%
    separate(date, into = c('Year', 'Month', 'Day'),sep = '-') %>%
    group_by(Year) %>%
    mutate(CumPrecip = cumsum(Rainfall), 
           Month = recode(Month, '05' ="May", '08'='Aug'), 
           Month = paste0(Month, ' ', Day)) %>%
    ungroup() %>%
    filter(Month %in% c('May 15', 'Aug 01' )) %>%
    mutate(season = recode(Month, 'May 15' = 'Spring', 'Aug 01' = 'Summer' )) %>%
    select(Year, season, CumPrecip)
  prcp_z <-
    prcp %>%
    filter(as.numeric(Year) %in% c(2017:2020)) %>%
    group_by(Year, season) %>%
    summarize(Mean = mean(CumPrecip), 
              .groups = 'drop') %>%
    left_join(by = 'season', 
              prcp %>%
                group_by(season) %>%
                summarize(HistMean = mean(CumPrecip, na.rm = T),
                          HistSD = sd(CumPrecip, na.rm = T),
                          .groups = 'drop') ) %>%
    mutate(z = (Mean - HistMean)/HistSD, 
           interp = case_when(
             z < -1 ~ "Below", 
             z > 1 ~ "Above", 
             TRUE ~ 'Within' )) 

\end{lstlisting}

**Figure 3** 

Compare 1990-1999 period to 2012-2022 for fuel and fire weather. 

\begin{lstlisting}[language=R]

# test historical fuel and fire weather across time periods 
    comp_tab <-
      hist_wx %>%
        group_by(season, variable) %>%
        group_modify(~ broom::tidy(lm(Value ~ period, data = .x))) %>%
        ungroup() %>%
        filter(term != '(Intercept)') %>%
        mutate(P = case_when(
          p.value > 0.05 ~ 'P > 0.05', 
          between(p.value, 0.00099, 0.01) ~ 'P < 0.01', 
          p.value < 0.001 ~ 'P < 0.001', 
          TRUE ~ paste0('P = ', round(p.value, 2)) ), 
          result = paste0('t = ', signif(statistic, 2), ", ", P)) %>%
        select(variable, season, result) %>%
        pivot_wider(names_from = season, 
                    values_from = result) 
\end{lstlisting}

Calculate $z$ scores. 

\begin{lstlisting}[language=R]

 hist_wx <-
    WxData$HourlyWx %>%
      filter(! date %in% RainyDays$date, 
             ! is.na(season)) %>%
      group_by(Year, date, season) %>%
      summarise_at(.vars = vars(c(DewPoint, RelHum, WindSpeed,VPD)),
                   .funs = c("mean")) %>%
      ungroup() %>%
      pivot_longer(names_to = 'variable', 
                   values_to = 'value', 
                   cols = DewPoint:VPD) %>%
      group_by(Year, season, variable) %>%
      summarise(Value = mean(value), 
                .groups = 'drop') %>%
      mutate(Year = as.character(Year), 
             #season = fct_rev(season), 
             period = case_when(
               Year %in% c(1990:1999) ~  '1990-1999', 
               Year %in% c(2012:2022) ~  '2012-2022', 
               TRUE ~ NA)) %>%
      filter(!is.na(period)) %>%
      bind_rows(WxData$Rainfall %>% 
                  filter(month(date) %in% c(04:09)) %>%
                  separate(date, into = c('Year', 'Month', 'Day'),sep = '-') %>%
                  group_by(Year) %>%
                  mutate(CumPrecip = cumsum(Rainfall), 
                         Month = recode(Month, '05' ="May", '08'='Aug'), 
                         season = paste0(Month, ' ', Day)) %>%
                  ungroup() %>%
                  filter(season %in% c('May 15', 'Aug 01' )) %>%
                  mutate(season = ifelse(season == 'May 15', 'Spring', 'Summer'), 
                         period = case_when(
                           Year %in% c(1990:1999) ~  '1990-1999', 
                           Year %in% c(2012:2022) ~  '2012-2022', 
                           TRUE ~ NA ) )  %>%
                  filter(!is.na(period)) %>%
                  select(Year, season, CumPrecip, period) %>%
                  pivot_longer(names_to = 'variable', 
                               values_to = 'Value', 
                               cols = CumPrecip))  %>%
      bind_rows(HistoricalSpectralData  %>% 
                  select(-pasture) %>%
                  filter(index == 'NDVI', 
                         range != '1990-2022') %>%
                  rename(Year = year, period = range, variable = index) ) 
    hist_wx %>%
      filter(as.numeric(Year) %in% c(2017:2020)) %>%
      group_by(Year, season, variable) %>%
      slice(1) %>%
      summarize(Mean = mean(Value), 
                .groups = 'drop') %>%
      left_join(by = c('season', 'variable'), 
                relationship = "many-to-many",
                hist_wx %>%
                  group_by(period, season, variable) %>%
                  summarize(HistMean = mean(Value, na.rm = T),
                            HistSD = sd(Value, na.rm = T),
                            .groups = 'drop') ) %>%
      mutate(z = (Mean - HistMean)/HistSD, 
             interp = case_when(
               z < -1 ~ "Below", 
               z > 1 ~ "Above", 
               TRUE ~ 'Within') )

\end{lstlisting}
